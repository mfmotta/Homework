{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from IPython.display import Image\n",
    "#from IPython.core.display import HTML \n",
    "\n",
    "from IPython.display import display, Math, Latex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Guidelines\n",
    "\n",
    "We want to predict a category, i.e. the skin color of the player. Let's figure out what to do following the diagram below, from scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://scikit-learn.org/stable/_static/ml_map.png\" width=\"700\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://scikit-learn.org/stable/_static/ml_map.png\", width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - The Data\n",
    "Let's take a look at the data and already drop what is not useful for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>player</th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>Alpha_3</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lucas-wilchez</td>\n",
       "      <td>Lucas Wilchez</td>\n",
       "      <td>Real Zaragoza</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1983</td>\n",
       "      <td>177.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GRC</td>\n",
       "      <td>0.326391</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.002696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>john-utaka</td>\n",
       "      <td>John Utaka</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>France</td>\n",
       "      <td>08.01.1982</td>\n",
       "      <td>179.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Right Winger</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>0.203375</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>-0.204082</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.061504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdon-prats</td>\n",
       "      <td>Abdón Prats</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>17.12.1992</td>\n",
       "      <td>181.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pablo-mari</td>\n",
       "      <td>Pablo Marí</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1993</td>\n",
       "      <td>191.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ruben-pena</td>\n",
       "      <td>Rubén Peña</td>\n",
       "      <td>Real Valladolid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>18.07.1991</td>\n",
       "      <td>172.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     playerShort         player             club leagueCountry    birthday  \\\n",
       "0  lucas-wilchez  Lucas Wilchez    Real Zaragoza         Spain  31.08.1983   \n",
       "1     john-utaka     John Utaka  Montpellier HSC        France  08.01.1982   \n",
       "2    abdon-prats    Abdón Prats     RCD Mallorca         Spain  17.12.1992   \n",
       "3     pablo-mari     Pablo Marí     RCD Mallorca         Spain  31.08.1993   \n",
       "4     ruben-pena     Rubén Peña  Real Valladolid         Spain  18.07.1991   \n",
       "\n",
       "   height  weight              position  games  victories    ...     rater2  \\\n",
       "0   177.0    72.0  Attacking Midfielder      1          0    ...       0.50   \n",
       "1   179.0    82.0          Right Winger      1          0    ...       0.75   \n",
       "2   181.0    79.0                   NaN      1          0    ...        NaN   \n",
       "3   191.0    87.0           Center Back      1          1    ...        NaN   \n",
       "4   172.0    70.0      Right Midfielder      1          1    ...        NaN   \n",
       "\n",
       "   refNum  refCountry  Alpha_3   meanIAT    nIAT     seIAT   meanExp    nExp  \\\n",
       "0       1           1      GRC  0.326391   712.0  0.000564  0.396000   750.0   \n",
       "1       2           2      ZMB  0.203375    40.0  0.010875 -0.204082    49.0   \n",
       "2       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "3       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "4       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "\n",
       "      seExp  \n",
       "0  0.002696  \n",
       "1  0.061504  \n",
       "2  0.001002  \n",
       "3  0.001002  \n",
       "4  0.001002  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CrowdstormingDataJuly1st.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['playerShort', 'player', 'club', 'leagueCountry', 'birthday', 'height',\n",
       "       'weight', 'position', 'games', 'victories', 'ties', 'defeats', 'goals',\n",
       "       'yellowCards', 'yellowReds', 'redCards', 'photoID', 'rater1', 'rater2',\n",
       "       'refNum', 'refCountry', 'Alpha_3', 'meanIAT', 'nIAT', 'seIAT',\n",
       "       'meanExp', 'nExp', 'seExp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146028\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CrowdstormingDataJuly1st.csv')\n",
    "\n",
    "\n",
    "#df = df.reset_index().drop_duplicates(subset='playerShort', keep='first') # if we want to have an unique entrance per player\n",
    "\n",
    "\n",
    "df = df.set_index('playerShort')\n",
    "\n",
    "df = df[['height','weight', 'position','games','victories', 'ties', 'defeats', 'goals',\n",
    "       'yellowCards', 'yellowReds', 'redCards','rater1', 'rater2','refNum','refCountry', 'meanIAT', 'nIAT', 'seIAT',\n",
    "       'meanExp', 'nExp', 'seExp']] # considering birthday (age) is not useful because we don't have the dates of individual matches\n",
    "\n",
    "\n",
    "#df.head()\n",
    "print(len(df))\n",
    "#df.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Attacking Midfielder', 'Right Winger', nan, 'Center Back',\n",
       "       'Right Midfielder', 'Left Fullback', 'Defensive Midfielder',\n",
       "       'Goalkeeper', 'Right Fullback', 'Left Winger', 'Left Midfielder',\n",
       "       'Center Forward', 'Center Midfielder'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.position.unique()  # We have to replace this with numerical values, as we do with the mapping below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction of the skin color is checked with rater1 and rater2. We chose to drop the NaN data in the raters and choose only the data on which they agree. \n",
    "\n",
    "Notice that for a Random Forest classifier, there is no need to normalize the features, as no comparison is made between their magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariele\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mariele\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mariele\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mariele\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\mariele\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87636"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='any', axis=0, inplace=True) # dropping NaN\n",
    "\n",
    "\n",
    "df2 = df[df.rater1 == df.rater2]\n",
    "df2['rater1'] = df2['rater1']*4  # the classifier only deals with integers\n",
    "df2['meanIAT'] = df2['meanIAT']*1000  # the classifier only deals with integers\n",
    "df2['meanExp'] = df2['meanExp']*100  # the classifier only deals with integers\n",
    "df2['seIAT'] = df2['seIAT']*10000  # the classifier only deals with integers\n",
    "df2['seExp'] = df2['seExp']*10000  # the classifier only deals with integers\n",
    "\n",
    "df2 = np.round(df2,0) # the classifier only deals with integers\n",
    "\n",
    "df2['position'] = df2['position'].map({'Goalkeeper':0, 'Attacking Midfielder':1, 'Right Winger':2, 'Left Winger':2,\n",
    "       'Center Back':3, 'Left Fullback':4,'Right Fullback':4, 'Defensive Midfielder':5, 'Left Midfielder':6,\n",
    "       'Right Midfielder':6,'Center Midfielder':7,'Center Forward':8}) # notice I've used symmetry between R and L\n",
    "\n",
    "\n",
    "# remember goalkeepers are less likely to get a card. Not taken into account yet\n",
    "\n",
    "df2.drop('rater2', axis=1, inplace=True)  \n",
    "\n",
    "df2 = df2[(df2 >= 0)].dropna(how='any') # dropping negative values and NaN\n",
    "\n",
    "#df2 = df2.dropna(how='any') # dropping NaN\n",
    "\n",
    "#df2 = df2[(df2 > 0).all(1)]  # dropping negative values\n",
    "\n",
    "#df2 = df2[df2['rater1'] >= 0]\n",
    "\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have labeled data, this means we can use a classification algorithm. Moreover, with *less* than 100K sample, we can use [Linear Support Vector Classification](https://en.wikipedia.org/wiki/Support_vector_machine). Now, for the moment, let's suppose it won't work, neither K-Neighbors Classifiers. Let's directly move to Ensemble Classifiers as asked in the HW assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>ties</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>redCards</th>\n",
       "      <th>rater1</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playerShort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alexander-tettey</th>\n",
       "      <td>180.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>325.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anders-lindegaard</th>\n",
       "      <td>193.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>325.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>andreas-beck</th>\n",
       "      <td>180.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>325.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antonio-rukavina</th>\n",
       "      <td>177.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>325.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ashkan-dejagah</th>\n",
       "      <td>181.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>325.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   height  weight  position  games  victories  ties  defeats  \\\n",
       "playerShort                                                                    \n",
       "alexander-tettey    180.0    68.0         5      1          0     0        1   \n",
       "anders-lindegaard   193.0    80.0         0      1          0     1        0   \n",
       "andreas-beck        180.0    70.0         4      1          1     0        0   \n",
       "antonio-rukavina    177.0    74.0         4      2          2     0        0   \n",
       "ashkan-dejagah      181.0    74.0         2      1          1     0        0   \n",
       "\n",
       "                   goals  yellowCards  yellowReds  redCards  rater1  refNum  \\\n",
       "playerShort                                                                   \n",
       "alexander-tettey       0            0           0         0     4.0       4   \n",
       "anders-lindegaard      0            0           0         0     1.0       4   \n",
       "andreas-beck           0            0           0         0     0.0       4   \n",
       "antonio-rukavina       0            1           0         0     0.0       4   \n",
       "ashkan-dejagah         0            0           0         0     2.0       4   \n",
       "\n",
       "                   refCountry  meanIAT   nIAT  seIAT  meanExp   nExp  seExp  \n",
       "playerShort                                                                  \n",
       "alexander-tettey            4    325.0  127.0   33.0     54.0  130.0  138.0  \n",
       "anders-lindegaard           4    325.0  127.0   33.0     54.0  130.0  138.0  \n",
       "andreas-beck                4    325.0  127.0   33.0     54.0  130.0  138.0  \n",
       "antonio-rukavina            4    325.0  127.0   33.0     54.0  130.0  138.0  \n",
       "ashkan-dejagah              4    325.0  127.0   33.0     54.0  130.0  138.0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['height', 'weight', 'position', 'games', 'victories', 'ties', 'defeats',\n",
       "       'goals', 'yellowCards', 'yellowReds', 'redCards', 'rater1', 'refNum',\n",
       "       'refCountry', 'meanIAT', 'nIAT', 'seIAT', 'meanExp', 'nExp', 'seExp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  III - Machine Learning\n",
    "\n",
    "Selecting the attributes and passing as X for scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df2.rater1\n",
    "\n",
    "df2.drop('rater1', axis=1, inplace=True)  \n",
    "X = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87636,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87636, 19)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Feature Selection\n",
    "\n",
    "Some tips on this can be found [here](https://www.quora.com/How-do-I-perform-feature-selection). For the moment, I'm gonna follow the more explicit and concise suggestions from [here](http://machinelearningmastery.com/feature-selection-machine-learning-python/), whose generalities are presented [here](http://machinelearningmastery.com/an-introduction-to-feature-selection/).\n",
    "\n",
    "The bottom line here is that we should do feature selection in a different datase than the training dataset, otherwise we might overfit the data.\n",
    "\n",
    "What about _cross-validation_? According to the [last link above](http://machinelearningmastery.com/an-introduction-to-feature-selection/), one should include feature selection within the inner-loop, i.e. feature selection should be performed on the prepared fold _right_ before the model is trained. Performing model selection and training on the selected features would generate biased results. It might occur that one model is enhanced by the selected feature and this model will get get better results, but that is just to an introduced bias. In other words,  *\"when performing feature selection on all the data and then cross-validate, the test data in each fold of the CV procedure was also used to choose the features and this is what biases the performance analysis\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "We will use cross-validation in order to tune the hyperparamaters. Give the discussion above, we would like to introduce the feature selection within the CV process.\n",
    "\n",
    "Below, we just use the default parameters of RF classifier and slip the data into 30% test and 70% training parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774561637062\n",
      "(61345, 19) (61345,)\n",
      "(26291, 19) (26291,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split #deprecated: from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# use train/test split with different random_state values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) #choose test size to be 30%\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print( X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73237715,  0.74712737,  0.75654088,  0.76016956,  0.74826771])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, X_train, y_train, cv=5) # the scores for each of the 5 folds of the CV\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "But the above doesn't help much, since these are just the scores considering all features and the default hyperparameters of RF. Let's consider a popular method for parameter estimation: grid search (not necessarily the best) with cross validation, [see](http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_digits.html#sphx-glr-auto-examples-model-selection-grid-search-digits-py). We start with simplicity, just exploring 2 HP: \n",
    "\n",
    "- number of trees: `n_estimators`\n",
    "- tree depth: `max_depth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [5, 15, 25], 'max_depth': [5, 15]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Grid search params\n",
    "n_trees = list(range(5,30,10))\n",
    "tree_depth = list(range(5,20,10))\n",
    "param_grid = dict(n_estimators=n_trees, max_depth=tree_depth)\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [5, 15, 25], 'max_depth': [5, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(rf, param_grid, cv=3, scoring='accuracy')  # TAKES FOREVER!!!\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56819115432014244"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'n_estimators': 15}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Scheme\n",
    "Implementing a CV scheme: (http://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html). Notice that all three methods below corresponde to the same CV (the `cross_val_score` helper giving a slightly different result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95777777777777773, 0.9376391982182628, 0.97327394209354123, 0.92873051224944325]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "svc = svm.SVC(C=1, kernel='linear')\n",
    "\n",
    "X_folds = np.array_split(X_digits, 4)\n",
    "y_folds = np.array_split(y_digits, 4)\n",
    "scores = list()\n",
    "for k in range(4):\n",
    "    # We use 'list' to copy, in order to 'pop' later on\n",
    "    X_train = list(X_folds)\n",
    "    X_test  = X_train.pop(k)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    y_train = list(y_folds)\n",
    "    y_test  = y_train.pop(k)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    scores.append(svc.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95777777777777773,\n",
       " 0.9376391982182628,\n",
       " 0.97327394209354123,\n",
       " 0.92873051224944325]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k_fold = KFold(n_splits=4)\n",
    "[svc.fit(X_digits[train], y_digits[train]).score(X_digits[test], y_digits[test])\n",
    "          for train, test in k_fold.split(X_digits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95594714,  0.94235033,  0.96868009,  0.92808989])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(svc, X_digits, y_digits, cv=4, n_jobs=-1) # the scores for each of the 4 nodes of the CV\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to repeat the above for my data set and with a RF Classifier. \n",
    "\n",
    "The CV below gives a significantly different score compared to the helper `cross_val_score`.  **Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72750924277694096, 0.77276461728056967, 0.7362042996029029]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_ = X\n",
    "y_ = y\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "X_folds = np.array_split(X_, n_folds)\n",
    "y_folds = np.array_split(y_, n_folds)\n",
    "scores = list()\n",
    "for k in range(n_folds):\n",
    "    # We use 'list' to copy, in order to 'pop' later on\n",
    "    X_train = list(X_folds)\n",
    "    X_test  = X_train.pop(k) # remove the item at the k position in the list, and return it\n",
    "    X_train = np.concatenate(X_train) # reconstructs the list without item k\n",
    "    y_train = list(y_folds)\n",
    "    y_test  = y_train.pop(k)\n",
    "    y_train = np.concatenate(y_train)\n",
    "    scores.append(rf.fit(X_train, y_train).score(X_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.572211  ,  0.76235794,  0.51658622])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X_, y_, cv=n_folds, n_jobs=1) # scores for each of the 4 folds # n_jobs=-1: no of jobs set to no of cores\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning HP\n",
    "\n",
    "For the moment, let's not do any feature selection. Let's do a personalized gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.73298644392715318, 0.7518143228810078, 0.74745538363229724, 0.76724177278743899, 0.74040348715139892, 0.74277694098315761, 0.74275411931169844, 0.75904879273357984]\n",
      "[0, 0, 0.73298644392715318, 0.7518143228810078, 0.76724177278743899, 0.74277694098315761, 0.75904879273357984]\n",
      "[0, 30, 30, 0.76724177278743899]\n"
     ]
    }
   ],
   "source": [
    "n_trees = list(range(20,40,10))\n",
    "tree_depth = list(range(20,40,10))\n",
    "\n",
    "X_ = X\n",
    "y_ = y\n",
    "\n",
    "n_folds = 2\n",
    "X_folds = np.array_split(X_, n_folds)\n",
    "y_folds = np.array_split(y_, n_folds)\n",
    "scores = [0]\n",
    "best_score = [0,0]\n",
    "i=1\n",
    "j=2\n",
    "\n",
    "for k in range(n_folds):\n",
    "    for l in range(len(n_trees)):\n",
    "        for m in range(len(tree_depth)):\n",
    "            rf = RandomForestClassifier(n_estimators=n_trees[l], max_depth=tree_depth[m])\n",
    "            # We use 'list' to copy, in order to 'pop' later on\n",
    "            X_train = list(X_folds)\n",
    "            X_test  = X_train.pop(k) # remove the item at the k position in the list, and return it\n",
    "            X_train = np.concatenate(X_train) # reconstructs the list without item k\n",
    "            y_train = list(y_folds)\n",
    "            y_test  = y_train.pop(k)\n",
    "            y_train = np.concatenate(y_train)\n",
    "            scores.append(rf.fit(X_train, y_train).score(X_test, y_test))\n",
    "            if scores[i] > scores[i-1]:\n",
    "                best_score.append(scores[i])\n",
    "                if best_score[j] > max(best_score[:j-1]):\n",
    "                    best = [k, n_trees[l],tree_depth[m], best_score[j]]\n",
    "                    #print(\"n_fold= %s,  n_tree= %s, tree_depth = %s, best score= %s  \" % (k, n_trees[l],tree_depth[m], best_score[j])) \n",
    "                j = j + 1\n",
    "            i = i + 1\n",
    "print (scores)\n",
    "print (best_score)\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the above using the helper `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=30, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=30, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [20, 30], 'max_depth': [20, 30]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "n_trees = list(range(20,40,10))\n",
    "tree_depth = list(range(20,40,10))\n",
    "param_grid = dict(n_estimators=n_trees, max_depth=tree_depth)\n",
    "\n",
    "\n",
    "grid = GridSearchCV(rf, param_grid, cv=2)  # TAKES FOREVER!!! # not setting the scoring uses the default one from the estimator\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.434606461834\n",
      "{'n_estimators': 20, 'max_depth': 30}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Including feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.82274407777625636, 0.69288876717330772, 0.834771098635264, 0.77150942535031264, 0.84145784837281479, 0.72919804646492314, 0.82637272353827196, 0.72730384773380807, 0.82171710256059149, 0.70112739057008533, 0.8434205121183076, 0.73965037199324479, 0.8263270801953535, 0.74549271988680454, 0.83999726139942488, 0.78832899721575611, 0.84812177643890641, 0.7680177096170524]\n",
      "[0, 0, 0.82274407777625636, 0.834771098635264, 0.84145784837281479, 0.82637272353827196, 0.82171710256059149, 0.8434205121183076, 0.8263270801953535, 0.83999726139942488, 0.84812177643890641]\n",
      "[0, 40, 40, 0.84812177643890641]\n"
     ]
    }
   ],
   "source": [
    "n_trees = list(range(20,50,10))\n",
    "tree_depth = list(range(20,50,10))\n",
    "\n",
    "\n",
    "n_folds = 2\n",
    "X_folds = np.array_split(X_, n_folds)\n",
    "y_folds = np.array_split(y_, n_folds)\n",
    "scores = [0]\n",
    "best_score = [0,0]\n",
    "i=1\n",
    "j=2\n",
    "\n",
    "for l in range(len(n_trees)):\n",
    "    for m in range(len(tree_depth)):\n",
    "        for k in range(n_folds):\n",
    "            X_train = list(X_folds) # We use 'list' to copy, in order to 'pop' later on\n",
    "            X_test  = X_train.pop(k) # remove the item at the k position in the list, and return it\n",
    "            X_train = np.concatenate(X_train) # reconstructs the list without item k\n",
    "            y_train = list(y_folds)\n",
    "            y_test  = y_train.pop(k)\n",
    "            y_train = np.concatenate(y_train)\n",
    "            \n",
    "            # doing feature selection\n",
    "            rf = RandomForestClassifier(n_estimators=n_trees[l], max_depth=tree_depth[m])\n",
    "            rf = rf.fit(X_train, y_train)\n",
    "            rf.feature_importances_  \n",
    "            model = SelectFromModel(rf, threshold=0.04, prefit=True)# selecting features with scores above 'threshold'\n",
    "            X_train = model.transform(X_train)\n",
    "            X_test = model.transform(X_test) ## is this really correct? otherwise I get an error.  ????\n",
    "            \n",
    "            scores.append(rf.fit(X_train, y_train).score(X_test, y_test))\n",
    "            if scores[i] > scores[i-1]:\n",
    "                best_score.append(scores[i])\n",
    "                if best_score[j] > max(best_score[:j-1]):\n",
    "                    best = [k, n_trees[l],tree_depth[m], best_score[j]]\n",
    "                    #print(\"n_fold= %s,  n_tree= %s, tree_depth = %s, best score= %s  \" % (k, n_trees[l],tree_depth[m], best_score[j])) \n",
    "                j = j + 1\n",
    "            i = i + 1\n",
    "print (scores)\n",
    "print (best_score)\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.79000000e+02   8.20000000e+01   2.00000000e+00 ...,  -2.00000000e+01\n",
      "    4.90000000e+01   6.15000000e+02]\n",
      " [  1.80000000e+02   6.80000000e+01   5.00000000e+00 ...,   5.40000000e+01\n",
      "    1.30000000e+02   1.38000000e+02]\n",
      " [  1.93000000e+02   8.00000000e+01   0.00000000e+00 ...,   5.40000000e+01\n",
      "    1.30000000e+02   1.38000000e+02]\n",
      " ..., \n",
      " [  1.90000000e+02   8.20000000e+01   3.00000000e+00 ...,   3.40000000e+01\n",
      "    7.97400000e+03   2.00000000e+00]\n",
      " [  1.86000000e+02   8.10000000e+01   6.00000000e+00 ...,   3.40000000e+01\n",
      "    7.97400000e+03   2.00000000e+00]\n",
      " [  1.74000000e+02   7.80000000e+01   4.00000000e+00 ...,   3.40000000e+01\n",
      "    7.97400000e+03   2.00000000e+00]]\n",
      "[[  1.79000000e+02   8.20000000e+01   2.00000000e+00   4.00000000e+01\n",
      "    4.90000000e+01]\n",
      " [  1.80000000e+02   6.80000000e+01   5.00000000e+00   1.27000000e+02\n",
      "    1.30000000e+02]\n",
      " [  1.93000000e+02   8.00000000e+01   0.00000000e+00   1.27000000e+02\n",
      "    1.30000000e+02]\n",
      " ..., \n",
      " [  1.90000000e+02   8.20000000e+01   3.00000000e+00   7.74900000e+03\n",
      "    7.97400000e+03]\n",
      " [  1.86000000e+02   8.10000000e+01   6.00000000e+00   7.74900000e+03\n",
      "    7.97400000e+03]\n",
      " [  1.74000000e+02   7.80000000e+01   4.00000000e+00   7.74900000e+03\n",
      "    7.97400000e+03]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, max_depth=10)\n",
    "\n",
    "X_train = list(X_folds) # We use 'list' to copy, in order to 'pop' later on\n",
    "X_test  = X_train.pop(1) # remove the item at the k position in the list, and return it\n",
    "X_train = np.concatenate(X_train) # reconstructs the list without item k\n",
    "y_train = list(y_folds)\n",
    "y_test  = y_train.pop(1)\n",
    "y_train = np.concatenate(y_train)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.feature_importances_  \n",
    "print(X_train)\n",
    "model = SelectFromModel(rf, threshold=0.04, prefit=True)\n",
    "X_train = model.transform(X_train)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Recursive Feature Elimination with Logistic Regression\n",
    "\n",
    "\n",
    "maybe this one does not make sense here... why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 4\n",
      "Selected Features: [ True False False False False False False False False False False False\n",
      "  True  True False False  True False False]\n",
      "Feature Ranking: [ 1  3 10  6 11 12  9 14  8 16 15  2  1  1  5 13  1  4  7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 4)\n",
    "fit = rfe.fit(X, y)\n",
    "print(\"Num Features: %d\" % fit.n_features_)\n",
    "print(\"Selected Features: %s\" % fit.support_)\n",
    "print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: [  9.44e-01   5.62e-02   3.11e-05]\n",
      "[[ -3.57e-04  -9.00e-04  -1.15e-04  -3.61e-04  -3.81e-04  -5.78e-05\n",
      "    7.72e-05  -2.07e-04  -3.88e-04   0.00e+00   0.00e+00   1.03e-01\n",
      "   -1.25e-03  -4.12e-03   6.97e-01  -1.91e-04  -3.01e-03   7.09e-01\n",
      "   -1.34e-03]\n",
      " [  1.39e-03   9.04e-05  -1.81e-03  -2.79e-03  -1.14e-03  -1.98e-03\n",
      "    3.33e-04  -2.49e-03  -1.03e-03   0.00e+00   0.00e+00   9.95e-01\n",
      "    9.78e-03  -6.21e-03  -7.36e-02   4.24e-04  -4.86e-03  -7.17e-02\n",
      "    1.37e-03]\n",
      " [  1.08e-02  -9.33e-02   1.50e-02   2.00e-01   5.90e-02   6.57e-02\n",
      "    7.58e-02   7.81e-03   7.51e-02   0.00e+00   0.00e+00   4.39e-03\n",
      "   -7.30e-01  -4.48e-01   2.04e-01  -2.86e-02  -2.73e-01  -2.06e-01\n",
      "   -1.97e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71785, 3)\n",
      "(71785,)\n",
      "(23929, 3)\n",
      "(23929,)\n"
     ]
    }
   ],
   "source": [
    "# default split is 75% for training and 25% for testing\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'intercept_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-8bb872f10aef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print the intercept and coefficients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'intercept_'"
     ]
    }
   ],
   "source": [
    "# print the intercept and coefficients\n",
    "print(rf.intercept_)\n",
    "print(rf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x199e4887a90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUMAAAFhCAYAAADqV8g6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuLxVnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x199e4887908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# allow plots to appear within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# visualize the relationship between the features and the response using scatterplots\n",
    "sns.pairplot(df3, x_vars=['rater1'], y_vars='redCards', size=5, aspect=0.9, kind='reg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
